PMID,Title,Authors,Journal,PublicationDate,Abstract
40914178,"Safety of artificial intelligence-assisted optical diagnosis for leaving colorectal polyps in situ during colonoscopy (PRACTICE): a non-inferiority, randomised controlled trial.",Antonelli G; Desideri F; Scarozza P; Andrisani G; Zerboni G; Furnari M; Bevilacqua N; Cossignani M; Di Fonzo M; Cereatti F; Navazzotti G; Antenucci C; Di Matteo FM; Bevivino G; Caruso A; Spadaccini M; Schiavone S; Grossi C; Rizkala T; Comberlato M; Bretthauer M; Sharma P; Von Renteln D; Rex DK; Correale L; Repici A; Mori Y; Iacopini F; Hassan C,The lancet. Gastroenterology & hepatology,2025 Oct,"BACKGROUND: Guidelines recommend leaving in situ rectosigmoid polyps diagnosed during colonoscopy that are 5 mm or smaller if the endoscopist optically predicts them to be non-neoplastic. However, no randomised controlled trial has been done to examine the efficacy and safety of this strategy. METHODS: This open-label, multicentre, non-inferiority, randomised controlled trial enrolled adults age 18 years or older undergoing colonoscopy for screening, surveillance, or clinical indications across four Italian centres. Eligible patients were randomised 1:1 (with stratification by patient sex, age, and previous adenoma removal) via a central web-based system, to either the leave-in-situ group, in which endoscopists could leave non-neoplastic lesions in place after optical diagnosis, or the resect-all group, in which all detected polyps were systematically removed, regardless of optical diagnosis. Patients and endoscopists were not masked to group allocation but pathologists and investigators assessing outcomes were masked. All procedures in both groups were done with the assistance of a computer-aided detection and diagnosis system. Endoscopists optically diagnosed lesions through a combination of white light, blue light, and computer-aided detection. The primary outcome was the adenoma detection rate (ADR), defined as the proportion of participants with at least one adenoma detected (per-patient analysis), assessed by intention-to-treat, to determine whether the leave-in-situ strategy was non-inferior to the resect-all approach, with an absolute 10% non-inferiority margin. This trial was registered with ClinicalTrials.gov (NCT05500248) and is completed. FINDINGS: Between Oct 1, 2022, and April 30, 2024, 1147 patients were recruited and 895 patients (507 [57%] females, 388 [43%] males, mean age 61.1 years [SD 9.8]) were randomly assigned to either the leave-in-situ group (n=441) or resect-all group (n=454). 197 adenomas or colorectal cancers were detected in the leave-in-situ group and 211 in the resect-all group; the ADR was 44.7% (95% CI 40.4 to 49.5) in the leave-in-situ group and 46.5% (41.8 to 51.2) in the resect-all group (absolute difference -1.8 percentage points, 95% CI -8.9 to 4.9; p(non-inferiority)=0.013). No colonoscopy-related complications, including perforation and bleeding, were reported in either group. INTERPRETATION: The leave-in-situ strategy through optical diagnosis with computer-assisted diagnosis support does not reduce oncological safety of colonoscopy, as measured by ADR. By reducing unnecessary polypectomies, this strategy could be considered as an attractive option in colonoscopy practice. FUNDING: European Society of Gastrointestinal Endoscopy."
40897750,A dual-stream deep learning framework for skin cancer classification using histopathological-inherited and vision-based feature extraction.,Almutairi SA,Scientific reports,2025 Sep 2,"Skin cancer, particularly melanoma, remains one of the most life-threatening forms of cancer worldwide, with early detection being critical for improving patient outcomes. Traditional diagnostic methods, such as dermoscopy and histopathology, are often limited by subjectivity, interobserver variability, and resource constraints. To address these challenges, this study proposes a dual-stream deep learning framework that combines histopathological-inherited and vision-based feature extraction for accurate and efficient skin lesion diagnosis. The framework uses the U-Net architecture for precise lesion segmentation, followed by a dual-stream approach: the first stream employs Virchow2, a pretrained model, to extract high-level histopathological embeddings, whereas the second stream uses Nomic, a vision-based model, to capture spatial and contextual information. The extracted features are fused and integrated to create a comprehensive representation of the lesion, which is then classified via a multilayer perceptron (MLP). The proposed approach is evaluated on the HAM10000 dataset, achieving a mean accuracy of 96.25% and a mean F1 score of 93.79% across 10 trials. Ablation studies demonstrate the importance of both feature streams, with the removal of either stream resulting in significant performance degradation. Comparative analysis with existing studies highlights the superiority of the proposed framework, which outperforms traditional single-modality approaches. The results underscore the potential of the dual-stream framework to enhance skin cancer diagnosis, offering a robust, interpretable, and scalable solution for clinical applications."
40877428,Dual-model approach for accurate chest disease detection using GViT and swin transformer V2.,Ahmad K; Rehman HU; Shah B; Ali F; Hussain I,Scientific reports,2025 Aug 28,"The precise detection and localization of abnormalities in radiological images are very crucial for clinical diagnosis and treatment planning. To build reliable models, large and annotated datasets are required that contain disease labels and abnormality locations. Most of the time, radiologists face challenges in identifying and segmenting thoracic diseases such as COVID-19, Pneumonia, Tuberculosis, and lung cancer due to overlapping visual patterns in X-ray images. This study proposes a dual-model approach: Gated Vision Transformers (GViT) for classification and Swin Transformer V2 for segmentation and localization. GViT successfully identifies thoracic diseases that exhibit similar radiographic features, while Swin Transformer V2 maps lung areas and pinpoints affected regions. Classification metrics, including precision, recall, and F1-scores, surpassed 0.95 while the Intersection over Union (IoU) score reached 90.98%. Performance assessment via Dice Coefficient, Boundary F1-Score, and Hausdorff Distance demonstrated the system's excellent effectiveness. This artificial intelligence solution will help radiologists in decreasing their mental workload while improving diagnostic precision in healthcare systems that face resource constraints. Transformer-based architectures show strong promise for enhancing medical imaging procedures, according to the study results. Future AI tools should build on this foundation, focusing on comprehensive and precise detection of chest diseases to support effective clinical decision-making."
40871840,Imaging Through Scattering Tissue Based on NIR Multispectral Image Fusion Technique.,Atiya N; Shemer A; Schwarz A; Beiderman Y; Danan Y,"Sensors (Basel, Switzerland)",2025 Aug 12,"Non-invasive diagnostics play a crucial role in medicine, and they ensure both contamination safety and patient comfort. The proposed study integrates hyperspectral imaging with advanced image fusion, enabling non-invasive, diagnostic procedure within tissue. It utilizes near-infrared (NIR) wavelength vision that is suitable for reflections from objects within a dispersive layer, enabling the reconstruction of internal tissue layers images. It can detect objects, including cancerous tumors (presented as phantoms), inside human tissue. This involves processing data from multiple images taken in different NIR bands and merging them through image fusion techniques. Our research demonstrates evident data about objects within the diffusive media, visible only in the reconstructed images. The experimental results demonstrate a significant correlation with the samples employed in the study's experimental design."
40841423,Performance of deep learning models for the classification and object detection of different oral white lesions using photographic images.,Khovidhunkit SP; Phosri K; Thanathornwong B; Rungraungrayabkul D; Poomrittigul S; Treebupachatsakul T,Scientific reports,2025 Aug 22,"Computer vision adjunctive technology for oral lesion diagnoses has been developed to detect and identify Oral Potentially Malignant Disorders (OPMDs) and non-OPMDs. The early detection of OPMDs can reduce the risk of oral cancer development, improving the survival rate of the patients. This study aims to evaluate the computer vision technique in the white oral lesion domain within the scope of photographic images. Deep learning techniques for the classification of Convolution Neural Networks (CNNs) and transformer neural networks, and one-stage models of YOLOv7 and YOLOv8 were utilized to classify and detect five classes of OPMDs and non-OPMDs oral white lesions including oral leukoplakia, oral lichen planus, pseudomembranous candidiasis, oral ulcers covered with pseudomembrane and other white benign oral lesions. From the evaluation results of classification, the IFormerBase model achieves overperformance compared to CNN models with accuracy, precision, and F1 score of more than 80% on the test set. The best model for object detection is YOLOv7 with 84.5% mean Average Precision (mAP) at Intersection over Union (IoU) threshold of 0.3 and 74.5% at IoU of 0.5 on the test set. Object detection results reveal promising automatic oral lesion identification, which can be further developed to enhance the lesion screening system."
